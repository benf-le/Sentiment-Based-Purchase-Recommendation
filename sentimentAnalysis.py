import pandas as pd
import streamlit as st
import numpy as np
import torch

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from transformers import AutoModel, AutoTokenizer

from cleandata import Text_PreProcessing_util


def load_bert():

    v_phobert = AutoModel.from_pretrained("vinai/phobert-base")

    v_tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base", use_fast=False)

    return v_phobert, v_tokenizer

phobert, tokenizer = load_bert()

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
# Báº¡n cáº§n thay Ä‘á»•i Ä‘Æ°á»ng dáº«n tá»›i mÃ´ hÃ¬nh phÃ¹ há»£p
model_paths = {
    "Ensemble BiLSTM CNN Model": "model/ensemble_bilstm_cnn.keras",
    "LSTM Model": "model/lstm.keras",
    "BiLSTM Model": "model/bilstm.keras",
    "GRU Model": "model/gru.keras",
    "BiGRU Model": "model/bigru.keras",
    # "CNN Model": "model/cnn.keras",
    "Fusion BiLSTM CNN Model": "model/fusion_bilstm_cnn.keras",
    "Fusion BiGRU CNN Model": "model/fusion_bigru_cnn.keras",
    "Ensemble BiGRU CNN Model": "model/ensemble_bigru_cnn.keras",
}
models = {name: load_model(path) for name, path in model_paths.items()}

EMBEDDING_DIM = 768  # DÃ¹ng embedding vector cá»§a PhoBERT
index2class = {0: "Positive", 1: "Negative"}  # Mapping nhÃ£n

def phobert_embed_sentence(padded, mask, model=phobert):
    padded = torch.tensor(padded).to(torch.long)
    mask = torch.tensor(mask)

    with torch.no_grad():
        last_hidden_states = model(input_ids=padded, attention_mask=mask)[0]
    vector = last_hidden_states[:, 0, :].numpy()  # Láº¥y embedding vector
    return vector.flatten()

def predict_texts(texts, tokenizer, max_length=20, model=phobert):
    embedded_data = []
    texts = Text_PreProcessing_util(texts)


    for text in texts:
        tokenized_line = tokenizer.encode(text, max_length=max_length, truncation=True)
        padded_line = pad_sequences([tokenized_line], maxlen=max_length, padding='post', value=1)
        mask = np.where(padded_line == 1, 0, 1)
        embedded_line = phobert_embed_sentence(padded_line, mask)
        embedded_data.append(embedded_line)

    embedded_data = np.array(embedded_data)

    # Kiá»ƒm tra input shape cá»§a model
    input_shape = model.input_shape
    if len(input_shape) == 3:
        # CÃ¡c mÃ´ hÃ¬nh nhÆ° BiLSTM, BiGRU yÃªu cáº§u reshape 3D input
        input_data = embedded_data.reshape(embedded_data.shape[0], -1, EMBEDDING_DIM)
    elif len(input_shape) == 2:
        # MÃ´ hÃ¬nh CNN hoáº·c cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng input 2D
        input_data = embedded_data.reshape(embedded_data.shape[0], EMBEDDING_DIM)
    else:
        raise ValueError(f"Unsupported model input shape: {input_shape}")

    predictions = model.predict(input_data)
    predicted_classes = ((predictions > 0.5) + 0).ravel()  # Chuyá»ƒn xÃ¡c suáº¥t thÃ nh nhÃ£n
    return predicted_classes

# Giao diá»‡n Streamlit
st.set_page_config(
    page_title="Sentiment Analysis App",
    page_icon="ðŸ˜Š",
    layout="wide",
)


# Sidebar
with st.sidebar:
    st.header("Applications")
    app_mode = st.radio("Choose an application", ["Sentiment Analysis","Sentiment-Based Purchase Recommendation"])

if app_mode == "Sentiment Analysis":
    st.title("Vietnamese Review Sentiment Analysis ðŸ˜ŠðŸ¤”ðŸ˜¢")
    st.write("PhÃ¢n tÃ­ch cáº£m xÃºc cá»§a ngÆ°á»i mua hÃ ng.")

    # Chá»n mÃ´ hÃ¬nh
    selected_model_name = st.selectbox("Select a trained model", list(models.keys()))
    selected_model = models[selected_model_name]

    # Nháº­p vÄƒn báº£n Ä‘áº§u vÃ o
    user_input = st.text_input("Input text", placeholder="Nháº­p vÄƒn báº£n táº¡i Ä‘Ã¢y...")
    if st.button("Analyze"):
        if user_input:
            try:
                # Dá»± Ä‘oÃ¡n cáº£m xÃºc
                predicted_class = predict_texts([user_input], tokenizer, model=selected_model)
                # st.success(f"Sentiment Prediction: **{index2class[predicted_class[0]]}**")
                # Kiá»ƒm tra káº¿t quáº£ vÃ  hiá»ƒn thá»‹ thÃ´ng bÃ¡o phÃ¹ há»£p
                if predicted_class[0] == 0:  # Náº¿u lÃ  Positive
                    st.success(f"Sentiment Prediction: **Positive**")
                else:  # Náº¿u lÃ  Negative
                    st.error(f"Sentiment Prediction: **Negative**")

            except Exception as e:
                st.error(f"Error: {e}")
        else:
            st.warning("Please enter text to analyze.")
elif app_mode == "Sentiment-Based Purchase Recommendation":
    st.title("Sentiment-Based Purchase Recommendation")
    st.write("Khuyáº¿n nghá»‹ Mua hÃ ng Dá»±a trÃªn káº¿t quáº£ Ä‘Ã¡nh giÃ¡ Cáº£m xÃºc cá»§a KhÃ¡ch hÃ ng")
    # Báº¡n cÃ³ thá»ƒ thÃªm chá»©c nÄƒng Corpus Analysis á»Ÿ Ä‘Ã¢y
    # Chá»n mÃ´ hÃ¬nh ngay tá»« Ä‘áº§u
    selected_model_name = st.selectbox("Select a trained model", list(models.keys()))
    selected_model = models[selected_model_name]

    # File uploader
    uploaded_file = st.file_uploader("Browse Corpus", type=["csv", "txt"], label_visibility="visible")

    if uploaded_file is not None:
        file_name = uploaded_file.name
        st.write(f"File uploaded: {file_name}")

        sentences=[]
        # Read file into a pandas dataframe if it's a CSV
        if file_name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            st.write("First few rows of the file:")
            st.write(df.head())  # Display first few rows of the uploaded CSV

            # Get list of sentences (assuming one column of text)
            if 'text' in df.columns:
                sentences = df['text'].tolist()
            else:
                st.error("No 'text' column found in CSV file.")

        # Read content if it's a TXT file
        elif file_name.endswith(".txt"):
            content = uploaded_file.getvalue().decode("utf-8")
            sentences = content.split("\n")
            st.text(content)  # Display content of the uploaded text file
        else:
            st.error("Unsupported file type. Please upload CSV or TXT files.")

        if 'sentences' in locals() and sentences:
            st.write("Sentences in the file:")

            with st.spinner('Processing... Please wait while we analyze the sentences'):
                results = []

                positive_count = 0
                negative_count = 0

                for i, sentence in enumerate(sentences):
                    predicted_class = predict_texts([sentence], tokenizer, model=selected_model)
                    sentiment = "Positive" if predicted_class[0] == 0 else "Negative"
                    results.append({"Sentence": sentence, "Sentiment": sentiment})

                    if sentiment == "Positive":
                        positive_count += 1
                    else:
                        negative_count += 1

                # Chuyá»ƒn danh sÃ¡ch káº¿t quáº£ thÃ nh DataFrame
                results_df = pd.DataFrame(results)

                # TÃ­nh tá»· lá»‡ pháº§n trÄƒm
                total_count = len(sentences)
                positive_percentage = (positive_count / total_count) * 100
                negative_percentage = (negative_count / total_count) * 100

                # Hiá»ƒn thá»‹ káº¿t quáº£
                st.write("Results:")
                st.dataframe(results_df)
                st.success('Finished processing all sentences!')

                # Hiá»ƒn thá»‹ tá»· lá»‡ pháº§n trÄƒm cáº£m xÃºc tÃ­ch cá»±c vÃ  tiÃªu cá»±c
                st.write(f"Positive Sentiment: {positive_percentage:.2f}%")
                st.write(f"Negative Sentiment: {negative_percentage:.2f}%")

                # Quyáº¿t Ä‘á»‹nh cÃ³ nÃªn mua hay khÃ´ng
                if positive_percentage > 70:
                    st.success("Recommendation: **Yes**, you should buy the product.")
                elif negative_percentage > 70:
                    st.error("Recommendation: **No**, you should not buy the product.")
                else:
                    st.info("Recommendation: **It's a mixed review**, consider other factors before deciding.")


        else:
            st.warning("No sentences found in the uploaded file.")
